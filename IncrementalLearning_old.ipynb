{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PYkg41lIrkSQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, os.path\n",
        "import csv \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import  StratifiedKFold\n",
        "from collections import namedtuple\n",
        "from sklearn import tree\n",
        "import math\n",
        "import numpy.matlib as mb\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "InpStLXKu8w-"
      },
      "outputs": [],
      "source": [
        "def isOnlyDigit(value):\n",
        "\n",
        "  for c in value:\n",
        "    if (c < '0' or c > '9') and c != ' ':\n",
        "      return False;\n",
        "      \n",
        "  return True; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xqvqimnyu-hs"
      },
      "outputs": [],
      "source": [
        "def meanCalculate(Data):\n",
        "\n",
        "    meanSumStore = np.zeros(27).astype(int)\n",
        "    meanCntStore = np.zeros(27).astype(int)\n",
        "    meanStore = np.zeros(27).astype(int)\n",
        "    tmpStore = np.zeros(27).astype(int)\n",
        "    Flag = True\n",
        "    totalCol = 0\n",
        "    testCnt = 0\n",
        "    for Row in Data : \n",
        "        n = len(Row)-1\n",
        "        totalCol = n\n",
        "        if Flag : \n",
        "            Flag = False\n",
        "            continue \n",
        "        \n",
        "        i = 0 \n",
        "        RowX = []\n",
        "\n",
        "        for Value in Row : \n",
        "            if(i != 2):\n",
        "                isString = False\n",
        "                if(isinstance(Value, str)):\n",
        "                    if isOnlyDigit(Value) == True and Value != \"\" and Value != \" \" and Value != \" \" and Value != \"  \":\n",
        "                      Value = int(Value)\n",
        "                    else:\n",
        "                      isString = True\n",
        "                if isString == False:\n",
        "                  meanSumStore[i] += int(Value)\n",
        "                  meanCntStore[i] += int(1)\n",
        "                  #testCnt += 1\n",
        "\n",
        "            i = i+1 \n",
        "\n",
        "\n",
        "    for x in range(0, totalCol):\n",
        "      if x == 2:\n",
        "        continue;\n",
        "      \n",
        "      meanStore[x] = int(math.floor(int(meanSumStore[x]) / meanCntStore[x]))\n",
        "      \n",
        "    return np.array(meanStore) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sPhXU7i5rkST"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(fileName):\n",
        "    Data = []\n",
        "    with open(fileName, 'r') as File: \n",
        "      csvReader = csv.reader(File)\n",
        "      for Row in csvReader:        \n",
        "        Data.append(Row) \n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    Flag = True\n",
        "    total7 = 0\n",
        "    total2 = 0\n",
        "    cnt = 0\n",
        "\n",
        "\n",
        "    meanValue = meanCalculate(Data);\n",
        "    featureList = ['Thana', 'District', 'Accident_Severity', 'Month', 'Year', 'Time',\n",
        "       'Junction_Type', 'Traffic_Control', 'Movement', 'Divider', 'Weather',\n",
        "       'Light', 'Road_Geometry', 'Surface_Condition', 'Surface_Type',\n",
        "       'Surface_Quality', 'Road_Class', 'Road_Feature', 'Location_Type',\n",
        "       'Vehicle_Type', 'Vehicle_Movement', 'Vehicle_Loading', 'Vehicle_Defect',\n",
        "       'Vehicle_Driver_Age', 'Vehicle_Alcohol', 'Vehicle_Seat_Belt']\n",
        "\n",
        "\n",
        "    #featureList = ['Accident_Severity','Location_Type','Divider','Movement','Road_Geometry','Light','Weather','Traffic_Control', 'Time','Vehicle_Defect', 'Road_Class']\n",
        "    #featureList = []\n",
        "    #featureList = ['Accident_Severity','Vehicle_Defect', 'Road_Geometry', 'Traffic_Control', 'Vehicle_Loading', 'Vehicle_Movement', 'Vehicle_Seat_Belt', 'Year', 'Junction_Type', 'Surface_Quality', 'Weather', 'Road_Class', 'Surface_Type', 'Light', 'District', 'Surface_Condition']\n",
        "    \n",
        "    mpFeature = np.zeros(27).astype(int)\n",
        "\n",
        "    for Row in Data :\n",
        "        i = 0 \n",
        "        for Value in Row :\n",
        "          ok = 0\n",
        "          if(i==0):\n",
        "            Value=\"Thana\"\n",
        "          print(Value)\n",
        "          for col in featureList:\n",
        "            if col == Value:\n",
        "              ok = 1;\n",
        "              break;\n",
        "          if(ok == 1):\n",
        "            mpFeature[i] = 1\n",
        "          i += 1\n",
        "        break;\n",
        "    print(mpFeature)\n",
        "\n",
        "    for Row in Data : \n",
        "        if Flag : \n",
        "            Flag = False\n",
        "            continue \n",
        "        i = 0 \n",
        "        n = len(Row)-1\n",
        "        RowX = []\n",
        "        cnt += 1\n",
        "\n",
        "        if(cnt == 12998 or cnt == 10427):\n",
        "          continue;\n",
        "        \n",
        "        for Value in Row : \n",
        "            if(mpFeature[i] == 0):\n",
        "              i += 1;\n",
        "              continue;\n",
        "            if(i == 2):\n",
        "                if(Value == \"7\"):\n",
        "                    total7 = cnt;\n",
        "                if(Value == \"2\"):\n",
        "                    total2 = cnt;\n",
        "\n",
        "                Y.append(Value)\n",
        "            else:\n",
        "                if(isinstance(Value, str)):\n",
        "                    #Value = int(Value);\n",
        "                    if isOnlyDigit(Value) == True and Value != \"\" and Value != \" \" and Value != \" \" and Value != \"  \":\n",
        "                      Value = int(Value)\n",
        "                    else:\n",
        "                      Value=meanValue[i]\n",
        "\n",
        "                RowX.append(int(Value))\n",
        "            i = i+1 \n",
        "        X.append(RowX)\n",
        "    \n",
        "    print(len(np.array(X)[0]))\n",
        "    return np.array(X) , np.array(Y) \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "Gs5Vxqj1nvwI",
        "outputId": "241c3e5b-c446-4e1e-a0a3-50128efbac4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thana\n",
            "District\n",
            "Accident_Severity\n",
            "Month\n",
            "Year\n",
            "Time\n",
            "Junction_Type\n",
            "Traffic_Control\n",
            "Movement\n",
            "Divider\n",
            "Weather\n",
            "Light\n",
            "Road_Geometry\n",
            "Surface_Condition\n",
            "Surface_Type\n",
            "Surface_Quality\n",
            "Road_Class\n",
            "Road_Feature\n",
            "Location_Type\n",
            "Vehicle_Type\n",
            "Vehicle_Movement\n",
            "Vehicle_Loading\n",
            "Vehicle_Defect\n",
            "Vehicle_Driver_Age\n",
            "Vehicle_Alcohol\n",
            "Vehicle_Seat_Belt\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "25\n",
            "25\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "DataX , DataY = LoadDataSet(\"Dataset\\\\Full_Final.csv\") # X ,Y\n",
        "UniqueClass = np.unique(DataY)  #unique class in DataY\n",
        "Labels = np.zeros(len(DataY))   #set all value 0 in Labels\n",
        "\n",
        "#print(\"Total Dataset Size \",len(DataY))\n",
        "#print(\"Total Unique Size \",len(UniqueClass))\n",
        "\n",
        "#make unique number in each unique class label and store all unique value in Labels\n",
        "#g = 1, b = 0 value set all labels\n",
        "\n",
        "for i  in range(0,len(DataY)):\n",
        "    for j in range(0,len(UniqueClass)):\n",
        "        if UniqueClass[j] == DataY [i] : \n",
        "            Labels[i] = j\n",
        "for i in range(0, len(DataY)):\n",
        "    DataY[i] = Labels[i]\n",
        "      \n",
        "featureList = ['Thana', 'District', 'Month', 'Year', 'Time',\n",
        "      'Junction_Type', 'Traffic_Control', 'Movement', 'Divider', 'Weather',\n",
        "      'Light', 'Road_Geometry', 'Surface_Condition', 'Surface_Type',\n",
        "      'Surface_Quality', 'Road_Class', 'Road_Feature', 'Location_Type',\n",
        "      'Vehicle_Type', 'Vehicle_Movement', 'Vehicle_Loading', 'Vehicle_Defect',\n",
        "      'Vehicle_Driver_Age', 'Vehicle_Alcohol', 'Vehicle_Seat_Belt']\n",
        "print(len(DataX[0]))\n",
        "\n",
        "print(len(featureList))\n",
        "df = pd.DataFrame(DataX, columns = featureList)\n",
        "df['Accident_Severity'] = DataY\n",
        "df.to_csv(\"processed_data.csv\", index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YFwz4oJCrkSW"
      },
      "outputs": [],
      "source": [
        "def TestLearn():\n",
        "    K = 5 \n",
        "    DataX , DataY = LoadDataSet(\"Full_Final.csv\") # X ,Y\n",
        "\n",
        "    DataX , DataY = shuffle(DataX , DataY)\n",
        "\n",
        "\n",
        "    #print(DataY[0], DataY[1], DataY[2]);\n",
        "\n",
        "    #numpy lib start\n",
        "    UniqueClass = np.unique(DataY)  #unique class in DataY\n",
        "    Labels = np.zeros(len(DataY))   #set all value 0 in Labels\n",
        "\n",
        "    print(\"Total Dataset Size \",len(DataY))\n",
        "    print(\"Total Unique Size \",len(UniqueClass))\n",
        "\n",
        "    #make unique number in each unique class label and store all unique value in Labels\n",
        "    #g = 1, b = 0 value set all labels\n",
        "    for i  in range(0,len(DataY)):\n",
        "        for j in range(0,len(UniqueClass)):\n",
        "            if UniqueClass[j] == DataY [i] : \n",
        "                Labels[i] = j\n",
        "\n",
        "    DataTrainCell = []\n",
        "    LabelTrainCell = []\n",
        "    DataTestCell = []\n",
        "    LabelTestCell = []\n",
        "\n",
        "    #make test train dataset n_splits \n",
        "    skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
        "    for train_index, test_index in skf.split(DataX, Labels):\n",
        "        #print(\"TRAIN:\", len(train_index) )\n",
        "        #print( \"TEST:\", test_index)\n",
        "        DataTrainCell.append(DataX[train_index])\n",
        "        DataTestCell.append(DataX[test_index])\n",
        "        LabelTrainCell.append(Labels[train_index])\n",
        "        LabelTestCell.append(Labels[test_index])\n",
        "    \n",
        "    #print(len(LabelTrainCell))\n",
        "\n",
        "    MyStructModel = namedtuple( \"MyStructModel\", \"Type\")\n",
        "    Model = MyStructModel (Type =\"Cart\")\n",
        "    \n",
        "    MyStructNet = namedtuple( \"MyStructNet\", \"base_classifier iterations mclass classifiers beta\")\n",
        "    Net = MyStructNet (base_classifier = Model ,iterations =  3 , mclass =len(UniqueClass) , \n",
        "                       classifiers = None , beta = None)\n",
        "    return Learn(Net , DataTrainCell,LabelTrainCell,DataTestCell,LabelTestCell)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2-_h7wI-rkSY"
      },
      "outputs": [],
      "source": [
        "def CalculateEpsilon (D , PredictionSet , Labels ) :\n",
        "    # where label i not equel to prediction set i then store this index number in ErrorIndeces then sum \n",
        "    # of all D of those index\n",
        "    PredictionSet = np.array(PredictionSet)\n",
        "    Labels = np.array(Labels)\n",
        "    #por valo babe poira bujar cesta kor\n",
        "    ErrorIndeces = np.where(PredictionSet !=Labels)[0]\n",
        "    EpsilonKT = sum(np.take(D, ErrorIndeces))\n",
        "    return EpsilonKT / (1 - EpsilonKT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jvx91xNmrkSZ"
      },
      "outputs": [],
      "source": [
        "def ClassifyEnsemble (NetBeta, Netmclass, NetClassifiers , Data, Label, Limit, NetClassifiers1):\n",
        "    Weights = []\n",
        "    for Value in (np.array(NetBeta)) : \n",
        "        #print(Value)\n",
        "        if Value == 0 :\n",
        "            np.inf\n",
        "            Weights.append(np.inf)\n",
        "        else :\n",
        "            Weights.append(math.log10(1/Value))\n",
        "\n",
        "    Weights = np.array(Weights)\n",
        "    P = np.zeros((len(Label),Netmclass))# p -> 2d array, row = length of label array, col = number of unique class\n",
        "\n",
        "    for k in range(0,Limit) :\n",
        "        PredictionK = NetClassifiers[k].predict(Data)\n",
        "        #print(k,\"---->\",len(PredictionK))\n",
        "        PredictionK = np.array(PredictionK)\n",
        "        #print(PredictionK.shape ,P.shape , Weights.shape )\n",
        "        \n",
        "        for m in range(0, len(PredictionK)) : \n",
        "            #print(\"[m]\" ,m )\n",
        "            #print(\"PredictionK[m]\" ,PredictionK[m] )\n",
        "            #print(\"P[m,PredictionK[m]] \" ,P[m][int(PredictionK[m])]  )\n",
        "            P[m][int(PredictionK[m])]  = P[m][int(PredictionK[m])] + Weights[k]\n",
        "\n",
        "    return np.argmax(P,axis=1) , np.matlib.repmat(np.sum(P,axis = 1)[..., None],1,2)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG385eJdes5X"
      },
      "source": [
        "1\n",
        "-----\n",
        "train -> x y\n",
        "\n",
        "test -> x y\n",
        "\n",
        "prediction <- x\n",
        "\n",
        "1\n",
        "\n",
        "1\n",
        "trainData-> x,y\n",
        "testData-> x,y\n",
        "\n",
        "2\n",
        "trainData-> x,y\n",
        "testData-> x,y\n",
        "\n",
        "3\n",
        "trainData-> x,y\n",
        "testData-> x,y\n",
        "\n",
        "\n",
        "2\n",
        "\n",
        "4\n",
        "\n",
        "trainData-> x,y\n",
        "testData-> x,y\n",
        "\n",
        "\n",
        "x1, y1\n",
        "x2, y2\n",
        "x3, y3\n",
        "\n",
        "1 0\n",
        "- -\n",
        "4 2\n",
        "\n",
        "x, y -> 1/0\n",
        "\n",
        "\n",
        "#adaboast\n",
        "#naive bayes\n",
        "#ann\n",
        "#dnn\n",
        "\n",
        "#use multiple algorithm in weak classifier\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V8FSQ2HXwFRV"
      },
      "outputs": [],
      "source": [
        "def preProcessY(DataY):\n",
        "  UniqueClass = np.unique(DataY)  #unique class in DataY\n",
        "  Labels = np.zeros(len(DataY))   #set all value 0 in Labels\n",
        "\n",
        "  #make unique number in each unique class label and store all unique value in Labels\n",
        "  #g = 1, b = 0 value set all labels\n",
        "  for i  in range(0,len(DataY)):\n",
        "      for j in range(0,len(UniqueClass)):\n",
        "          if UniqueClass[j] == DataY [i] : \n",
        "              Labels[i] = j\n",
        "  return Labels;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ggwu3YYIrkSb"
      },
      "outputs": [],
      "source": [
        "def Learn(Net , DataTrain , LabelTrain, DataTest, LabelTest):\n",
        "    Tk = Net.iterations #number of classifiers to generate\n",
        "    K = len(DataTrain) #number of data sets \n",
        "    ###### porer code ta kaj na korle aita use kormu\n",
        "    #NetClassifiers = []\n",
        "    #for i in range(0,Tk*K) : \n",
        "    #    NetClassifiers.append([])\n",
        "    #NetClassifiers = np.array(NetClassifiers)\n",
        "    #\n",
        "\n",
        "    DataX , DataY = LoadDataSet(\"Dataset\\\\Full_Final.csv\") # X ,Y\n",
        "    DataX , DataY = shuffle(DataX , DataY)\n",
        "    DataY = preProcessY(DataY)\n",
        "\n",
        "\n",
        "    NetClassifiers = []\n",
        "    NetClassifiers1 = []\n",
        "    NetBeta = []\n",
        "    ClassifierCout = 0\n",
        "    Error = []\n",
        "\n",
        "    tError = 30\n",
        "    \n",
        "    for IndexK in range(0,K):\n",
        "        \n",
        "        DataTrainK = DataTrain[IndexK]\n",
        "        LabelTrainK = LabelTrain[IndexK]\n",
        "        DataTestK = DataTest[IndexK]\n",
        "        LabelTestK = LabelTest[IndexK]\n",
        "        TrainLength = len(LabelTrainK)\n",
        "        #eto tuk\n",
        "        D = np.ones(TrainLength) / TrainLength\n",
        "\n",
        "        if IndexK > 0 :\n",
        "            #print(\"if K > 0 :\")\n",
        "            PredictionsTrainEnsemble , Posterior = ClassifyEnsemble (NetBeta, Net.mclass,\n",
        "                                NetClassifiers ,DataTrainK, LabelTrainK, ClassifierCout, NetClassifiers1)\n",
        "            EpsilonKT = CalculateEpsilon(D,PredictionsTrainEnsemble,LabelTrainK)\n",
        "            BetaKT = EpsilonKT / (1-EpsilonKT)\n",
        "            MatchedIndeces = np.where(PredictionsTrainEnsemble ==LabelTrainK)[0]\n",
        "            np.put(D, MatchedIndeces, BetaKT* np.take(D, MatchedIndeces))\n",
        "\n",
        "        #print(\"Dataset k = \",IndexK,\" ----------------------------------------\")\n",
        "       # ClassifierCout = 0\n",
        "        for t in range(0,Tk) :\n",
        "            #step 1 \n",
        "            D = D / np.sum(D)#1\n",
        "\n",
        "            if len(DataTrainK) == len(LabelTrainK):\n",
        "\n",
        "                clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
        "\n",
        "                clf = tree.DecisionTreeClassifier()\n",
        "                #clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "                clf1 = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "                NetClassifiers1.append(clf1.fit(DataTrainK, LabelTrainK))\n",
        "                NetClassifiers.append(clf.fit(DataTrainK, LabelTrainK))\n",
        "                \n",
        "                #step 4\n",
        "                PredictionOnTrainSet = NetClassifiers[ClassifierCout].predict(DataTrainK)\n",
        "                betaResult = CalculateEpsilon(D,PredictionOnTrainSet , LabelTrainK)\n",
        "\n",
        "                NetBeta.append(betaResult)  \n",
        "\n",
        "\n",
        "                #print(\"Iteration t= \", t)\n",
        "                #print(\"Beta t =\", CalculateEpsilon(D,PredictionOnTrainSet , LabelTrainK))\n",
        "                \n",
        "                #print(\"NetBeta :\" , NetBeta)\n",
        "                PredictionsTrainEnsemble , Posterior = ClassifyEnsemble (NetBeta, Net.mclass,\n",
        "                                NetClassifiers ,DataTrainK, LabelTrainK, ClassifierCout, NetClassifiers1)\n",
        "                \n",
        "                #print(PredictionsTrainEnsemble);\n",
        "                \n",
        "                EpsilonKT = CalculateEpsilon(D,PredictionsTrainEnsemble,LabelTrainK)\n",
        "                if EpsilonKT > 0.5 : \n",
        "                    EpsilonKT = 0.5\n",
        "                BetaKT = EpsilonKT / (1-EpsilonKT)\n",
        "                \n",
        "                MatchedIndeces = np.where(PredictionsTrainEnsemble ==LabelTrainK)[0]\n",
        "                np.put(D, MatchedIndeces, BetaKT* np.take(D, MatchedIndeces))\n",
        "                D = D / np.sum(D)\n",
        "\n",
        "\n",
        "                PredictionsTestEnmble , Posterior = ClassifyEnsemble (NetBeta, Net.mclass,\n",
        "                                NetClassifiers ,DataTestK, LabelTestK, ClassifierCout, NetClassifiers1)\n",
        "                \n",
        "                totalMissClassifi = len(np.where(PredictionsTestEnmble != LabelTestK)[0])\n",
        "                totalClassifi = len(LabelTestK) - totalMissClassifi\n",
        "                errorRate = (totalMissClassifi / len(LabelTestK)) * 100\n",
        "                errorRate = round(errorRate,2)\n",
        "                Error.append(errorRate)\n",
        "\n",
        "                FDTree = tree.DecisionTreeClassifier()\n",
        "                FDClassifier = FDTree.fit(DataTrainK, LabelTrainK)\n",
        "\n",
        "                fPredict = FDClassifier.predict(DataTestK)\n",
        "                fPredict = np.array(fPredict)\n",
        "                FtotalMissClassifi = len(np.where(fPredict != LabelTestK)[0])\n",
        "                FerrorRate = (FtotalMissClassifi / len(LabelTestK)) * 100\n",
        "                FerrorRate = round(FerrorRate,2)\n",
        "\n",
        "                print(len(LabelTestK), totalClassifi, totalMissClassifi, FtotalMissClassifi, errorRate, FerrorRate)\n",
        "                \n",
        "                #print(\"result\");\n",
        "                #ac = accuracy_score(LabelTestK, PredictionsTestEnmble)\n",
        "                #print(ac)\n",
        "                #Error.append(ac)\n",
        "                #tError -= random.randint(1,3)\n",
        "                #PredictionOnTestSet = NetClassifiers[ClassifierCout].predict(DataTestK)\n",
        "                #NetBeta = CalculateEpsilon(D,PredictionOnTrainSet , LabelTrainK)\n",
        "                #PredictionOnTestSet = np.array(PredictionOnTestSet)\n",
        "                #LabelTestK = np.array(LabelTest[IndexK])\n",
        "                #TestSetError = np.where(PredictionOnTestSet !=LabelTestK)[0]\n",
        "                #print(\"TestSetError\" , TestSetError)\n",
        "                #b = sum(np.take(D, TestSetError))\n",
        "                #print(\"b\" , b)\n",
        "\n",
        "            else:\n",
        "                print(\"Error\")\n",
        "            if (Error[ClassifierCout]) == 0 : \n",
        "                print(\"t = \" , t , \" , Error 0 asse\")\n",
        "            ClassifierCout = ClassifierCout + 1 \n",
        "\n",
        "            \n",
        "    return Error , ClassifierCout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0HbIqmirkSd",
        "outputId": "993656b1-5125-4aec-cd30-1f70af2b5c9a"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Full_Final.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Avia_thesis\\code\\Total\\IncrementalLearning (1).ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000011?line=0'>1</a>\u001b[0m Error , Count \u001b[39m=\u001b[39m TestLearn()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000011?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(Count)\n",
            "\u001b[1;32md:\\Avia_thesis\\code\\Total\\IncrementalLearning (1).ipynb Cell 6'\u001b[0m in \u001b[0;36mTestLearn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTestLearn\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=1'>2</a>\u001b[0m     K \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m \n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=2'>3</a>\u001b[0m     DataX , DataY \u001b[39m=\u001b[39m LoadDataSet(\u001b[39m\"\u001b[39;49m\u001b[39mFull_Final.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# X ,Y\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=4'>5</a>\u001b[0m     DataX , DataY \u001b[39m=\u001b[39m shuffle(DataX , DataY)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=7'>8</a>\u001b[0m     \u001b[39m#print(DataY[0], DataY[1], DataY[2]);\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=8'>9</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000005?line=9'>10</a>\u001b[0m     \u001b[39m#numpy lib start\u001b[39;00m\n",
            "\u001b[1;32md:\\Avia_thesis\\code\\Total\\IncrementalLearning (1).ipynb Cell 4'\u001b[0m in \u001b[0;36mLoadDataSet\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLoadDataSet\u001b[39m(fileName):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000003?line=1'>2</a>\u001b[0m     Data \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000003?line=2'>3</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(fileName, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m File: \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000003?line=3'>4</a>\u001b[0m       csvReader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(File)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000003?line=4'>5</a>\u001b[0m       \u001b[39mfor\u001b[39;00m Row \u001b[39min\u001b[39;00m csvReader:        \n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Full_Final.csv'"
          ]
        }
      ],
      "source": [
        "Error , Count = TestLearn()\n",
        "print(Count)\n",
        "#print(len(Error))\n",
        "#print(Error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1aUbESWqrkSh",
        "outputId": "06b6c0e0-b1fe-415e-88b9-3398aedfe6ba"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Error' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Avia_thesis\\code\\Total\\IncrementalLearning (1).ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000012?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(Error)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000012?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39msome numbers\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Avia_thesis/code/Total/IncrementalLearning%20%281%29.ipynb#ch0000012?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Error' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(Error)\n",
        "plt.ylabel('some numbers')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "IncrementalLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
